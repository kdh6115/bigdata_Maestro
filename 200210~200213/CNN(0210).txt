CNN(Convolution Neural Network) -> 망의 깊이가 제일 중요한 요소
주변의 픽셀을 고려 => 적분을 통해 면적 구함
filter , Padding , stride => conv2d의 매개변수
pooling					=> model(sequential, model(class base로 구성하고 싶을때), functional-multi in, multi out) -> compile(backend-tensorflow, CNTK, theamo) -> fit -> evaluate -> predict
 	=> 이미지의 특성을 뽑아냄
filter size가 크면 큰 특성, 작으면 작은 특성
크게 하면 특징 손실이 일어나고 사이즈 작으면 깊게(VGGNET16, 19) 할 수 있다.
					   RESNET 152   (vggnet, resnet으로 동영상 처리 가능)
identity : 회로를 정규화, 이전것을 고려  ①   ->    ②   ->    ③
 			  	    특징부여    1번이 추출하고 난다음 1번을 다시 고려
inception
Image Data Generator => Image Augmentation(flip, scale)을 통해서 이미지 부족문제 해결
		        memory, file(minibatch이용)지원
transfer learning : 데이터부족문제 해결
transduction : 반지도학습
이미지를 잘 처리하기 위해서 필터의 사이즈, layer의 깊이, 원본의 resolution(해상도) => Efficient Net(요즘 성능 제일 좋음)

비지도 & 지도 -> reimforce learning -> transfer learning
범용적, 가중치 -> pretrain -> Domain에 적용
Finetuning : pretrain된걸 FFNN 수정

global average pooling : 다차원의 이미지를 1차원으로 
※ conv연산이 끝나면 flatten 





https://bskyvision.com/504      ( VGGnet16)
https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/    (Augmentation)
https://eehoeskrap.tistory.com/186 (fine tunning)
https://jetsonaicar.tistory.com/16   (Global Average Pooling - GAP)