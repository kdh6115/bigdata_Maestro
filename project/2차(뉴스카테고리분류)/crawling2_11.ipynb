{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:JVM is already running. Do not init twice!\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from gensim.models import Word2Vec\n",
    "import csv\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Hannanum\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import csv\n",
    "import logging\n",
    "from konlpy import jvm\n",
    "logger = logging.getLogger(__name__)\n",
    "jvm.init_jvm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_excel(\"data.xlsx\")\n",
    "data_set = data_set.iloc[:,1:]\n",
    "data_set.rename({0:'news'},axis=1, inplace= True)\n",
    "data_label = {1:'culture',2:'global',3:'politic',4:'society',5:'economy'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_18\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_set)) :\n",
    "    data_set['news'][i] = re.sub('[^a-zA-Z0-9 ㄱ-ㅣ가-힣]', '', data_set['news'][i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.iloc[:40000,:]  # 5만 이상 데이터는 오류 발생(왜?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>추하다 vs 갈라서자바른미래 갈등 폭발</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울경기 호우주의보호우경보로 격상 시간당 50mm 이상 폭우</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갤럭시 폴드 불량강화유리 떼내고 고장났다 떼쓰는 격</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>신종 코로나 불안감에 쿠팡 주문량 역대 최대김범석 비상 상황</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>삼성 퇴직 임원도 당했다DLS 손실 눈덩이</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                news  label\n",
       "0              추하다 vs 갈라서자바른미래 갈등 폭발      3\n",
       "1  서울경기 호우주의보호우경보로 격상 시간당 50mm 이상 폭우      1\n",
       "2       갤럭시 폴드 불량강화유리 떼내고 고장났다 떼쓰는 격      5\n",
       "3  신종 코로나 불안감에 쿠팡 주문량 역대 최대김범석 비상 상황      1\n",
       "4            삼성 퇴직 임원도 당했다DLS 손실 눈덩이      5"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun(text):\n",
    "    tokenizer = Twitter()\n",
    "    nouns = tokenizer.nouns(text)\n",
    "    return [n for n in nouns]\n",
    "\n",
    "def get_noun2(text):\n",
    "    tokenizer = Hannanum()\n",
    "    nouns = tokenizer.nouns(text)\n",
    "    return [n for n in nouns]\n",
    "\n",
    "def get_noun3(text):\n",
    "    tokenizer = Okt()\n",
    "    nouns = tokenizer.nouns(text)\n",
    "    return [n for n in nouns]\n",
    "\n",
    "def get_morphs3(text):\n",
    "    tokenizer = Okt()\n",
    "    morphs = tokenizer.morphs(text)\n",
    "    return [n for n in morphs]\n",
    "\n",
    "def get_noun4(text):\n",
    "    tokenizer = Komoran()\n",
    "    nouns = tokenizer.nouns(text)\n",
    "    return [n for n in nouns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data_set, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=train_set.reset_index(drop=True)\n",
    "test_set=test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_transform = CV.fit_transform(train_set[\"news\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_set = data_set['label']\n",
    "label_set = train_set['label']\n",
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>날씨 구름 많고 포근한 하루미세먼지 농도 짙어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>해외 이모저모 내 아기 놔줘 만류에도 위험한 침례 강행</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>모든 자영업자 산재보험 가입당정청 사각지대 해소방안</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>와이파이 여론 역풍에한걸음씩 물러선 현대차 노사</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정국 혼란 베네수엘라에 정전사태학교 휴업병원 발동동</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>유시민 살인자 북송 비난 자기 집 방 하나 내주든가</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>친구 흉기로 살해 초등생 여아 형사처벌 안 받나 괴롭힘 당해</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>여야4당 대표 봉하마을 집결노무현 10주기 추도식 참석</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>저축은행 사태 트라우마 증권사 부동산 PF 쏠림에 제동 건 금</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>달걀 1주일에 3개 이상 먹으면 심장질환조기사망 위험 연구</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     news  label\n",
       "0              날씨 구름 많고 포근한 하루미세먼지 농도 짙어요      1\n",
       "1          해외 이모저모 내 아기 놔줘 만류에도 위험한 침례 강행      2\n",
       "2           모든 자영업자 산재보험 가입당정청 사각지대 해소방안       3\n",
       "3              와이파이 여론 역풍에한걸음씩 물러선 현대차 노사      5\n",
       "4            정국 혼란 베네수엘라에 정전사태학교 휴업병원 발동동      2\n",
       "...                                   ...    ...\n",
       "27995        유시민 살인자 북송 비난 자기 집 방 하나 내주든가      3\n",
       "27996   친구 흉기로 살해 초등생 여아 형사처벌 안 받나 괴롭힘 당해      4\n",
       "27997      여야4당 대표 봉하마을 집결노무현 10주기 추도식 참석      3\n",
       "27998  저축은행 사태 트라우마 증권사 부동산 PF 쏠림에 제동 건 금      5\n",
       "27999    달걀 1주일에 3개 이상 먹으면 심장질환조기사망 위험 연구      1\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_18\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Kkma\n",
    "tf.reset_default_graph()\n",
    "twitter = Twitter()\n",
    "token = []\n",
    "embeddingmodel = []\n",
    "for i in range(len(data_set)):\n",
    "    label = data_set['label']\n",
    "    sentence = twitter.pos(data_set['news'][i], norm=True, stem=True)\n",
    "    temp = []\n",
    "    temp_embedding = []\n",
    "    all_temp = []\n",
    "    for k in range(len(sentence)):\n",
    "        temp_embedding.append(sentence[k][0])\n",
    "        temp.append(sentence[k][0] + '/' + sentence[k][1])\n",
    "    all_temp.append(temp)\n",
    "    embeddingmodel.append(temp_embedding)\n",
    "    \n",
    "    all_temp.append(label[i])\n",
    "    token.append(all_temp)\n",
    "    \n",
    "embeddingmodel = []\n",
    "for i in range(len(label_set)):\n",
    "    temp_embeddingmodel = []\n",
    "    for k in range(len(token[i][0])):\n",
    "        temp_embeddingmodel.append(token[i][0][k])\n",
    "    embeddingmodel.append(temp_embeddingmodel)\n",
    "embedding  = Word2Vec(embeddingmodel, size = 300, window =5, min_count = 10,\n",
    "                      iter = 5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_18\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('신종/Noun', 0.9829598665237427),\n",
       " ('우한/Noun', 0.9699337482452393),\n",
       " ('폐렴/Noun', 0.9631495475769043),\n",
       " ('확/Noun', 0.9496662616729736),\n",
       " ('코로나바이러스/Noun', 0.9424995183944702),\n",
       " ('국내/Noun', 0.9265066385269165),\n",
       " ('전세기/Noun', 0.9231536388397217),\n",
       " ('번째/Suffix', 0.9182091951370239),\n",
       " ('진자/Noun', 0.9165610671043396),\n",
       " ('확진/Noun', 0.9163594245910645)]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.most_similar('코로나/Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['추하다/Adjective', 'vs/Alpha', '갈라/Noun', '서자/Noun', '바른/Modifier', '미래/Noun', '갈등/Noun', '폭발/Noun']\n",
      "['서울/Noun', '경기/Noun', '호우/Noun', '주의보/Noun', '호우경보/Noun', '로/Josa', '격상/Noun', '시간/Noun', '당/Suffix', '50/Number', 'mm/Alpha', '이상/Noun', '폭우/Noun']\n",
      "['갤럭시/Noun', '폴드/Noun', '불량/Noun', '강화유리/Noun', '떼다/Verb', '고장/Noun', '나다/Verb', '떼쓰다/Verb', '격/Noun']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>추하다 vs 갈라서자바른미래 갈등 폭발</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울경기 호우주의보호우경보로 격상 시간당 50mm 이상 폭우</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갤럭시 폴드 불량강화유리 떼내고 고장났다 떼쓰는 격</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>신종 코로나 불안감에 쿠팡 주문량 역대 최대김범석 비상 상황</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>삼성 퇴직 임원도 당했다DLS 손실 눈덩이</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>오늘부터 장마 시작중부는 낮까지 폭염</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>환자 밀접접촉자도 아닌데국내 첫 2차 감염</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>음원 사재기 의혹 닐로 SNS 댓글 차단</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>풀영상 이인영 한국당 비례대표 폐지 주장은 어깃장</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>나경원 정부 청년정책 청년들 스스로 일자리 단념하게 해</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    news  label\n",
       "0                  추하다 vs 갈라서자바른미래 갈등 폭발      3\n",
       "1      서울경기 호우주의보호우경보로 격상 시간당 50mm 이상 폭우      1\n",
       "2           갤럭시 폴드 불량강화유리 떼내고 고장났다 떼쓰는 격      5\n",
       "3      신종 코로나 불안감에 쿠팡 주문량 역대 최대김범석 비상 상황      1\n",
       "4                삼성 퇴직 임원도 당했다DLS 손실 눈덩이      5\n",
       "...                                  ...    ...\n",
       "39995               오늘부터 장마 시작중부는 낮까지 폭염      4\n",
       "39996            환자 밀접접촉자도 아닌데국내 첫 2차 감염      4\n",
       "39997             음원 사재기 의혹 닐로 SNS 댓글 차단      4\n",
       "39998        풀영상 이인영 한국당 비례대표 폐지 주장은 어깃장      3\n",
       "39999     나경원 정부 청년정책 청년들 스스로 일자리 단념하게 해      3\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(token[0][0])\n",
    "print(token[1][0])\n",
    "print(token[2][0])\n",
    "data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_hot(data):\n",
    "       \n",
    "    index_dict = {value:index for index,value in enumerate(set(data))}\n",
    "    result = []\n",
    "\n",
    "    for value in data:\n",
    "\n",
    "        one_hot = np.zeros(len(index_dict))\n",
    "        index = index_dict[value]\n",
    "        one_hot[index] = 1\n",
    "        result.append(one_hot)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def Convert2Vec(model_name, doc): \n",
    "    #train_X_ = W2V.Convert2Vec(\"Word2Vec_csv_article.embedding\",train_X)\n",
    "    word_vec = []\n",
    "    model = model_name\n",
    "    for sent in doc:\n",
    "        sub = []\n",
    "        for word in sent:\n",
    "            if word in model.wv.vocab:\n",
    "                sub.append(model.wv[word]) \n",
    "            else:\n",
    "                sub.append(np.random.uniform(-0.25,0.25,300)) # 사전에 해당 워드가 없으면 랜덤한 vector 생성하게 해줌\n",
    "        word_vec.append(sub)\n",
    "\n",
    "    return word_vec\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_LSTM():\n",
    "    \n",
    "    def __init__(self, lstm_units, num_class, keep_prob):\n",
    "        \n",
    "        self.lstm_units = lstm_units\n",
    "        \n",
    "        with tf.variable_scope('forward', reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            self.lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n",
    "            self.lstm_fw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n",
    "            \n",
    "        with tf.variable_scope('backward', reuse = tf.AUTO_REUSE):\n",
    "            \n",
    "            self.lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, forget_bias=1.0, state_is_tuple=True)\n",
    "            self.lstm_bw_cell = tf.contrib.rnn.DropoutWrapper(self.lstm_fw_cell, output_keep_prob = keep_prob)\n",
    "        \n",
    "        with tf.variable_scope('Weights', reuse = tf.AUTO_REUSE):\n",
    "           \n",
    "            self.W = tf.get_variable(name=\"W\", shape=[2 * lstm_units, num_class],\n",
    "                                dtype=tf.float32, initializer = tf.contrib.layers.xavier_initializer())\n",
    "            self.b = tf.get_variable(name=\"b\", shape=[num_class], dtype=tf.float32,\n",
    "                                initializer=tf.zeros_initializer())\n",
    "            \n",
    "            \n",
    "    def logits(self, X, W, b, seq_len):\n",
    "        \n",
    "        (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(self.lstm_fw_cell, self.lstm_bw_cell,dtype=tf.float32,\n",
    "                                                                            inputs = X, sequence_length = seq_len)\n",
    "\n",
    "        outputs = tf.concat([states[0][1], states[1][1]], axis=1)\n",
    "        pred = tf.matmul(outputs, W) + b        \n",
    "        return pred\n",
    "        \n",
    "    def model_build(self, logits, labels, learning_rate = 0.001):\n",
    "        \n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits , labels = labels)) # Softmax loss\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss) \n",
    "            merged = tf.summary.merge_all()\n",
    "        return loss, optimizer, merged\n",
    "    \n",
    "    def graph_build(self, avg_loss, avg_acc):\n",
    "        \n",
    "        tf.summary.scalar('Loss', avg_loss)\n",
    "        tf.summary.scalar('Accuracy', avg_acc)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zero_padding(train_batch_X, Batch_size, Maxseq_length, Vector_size):\n",
    "        \n",
    "    zero_pad = np.zeros((Batch_size, Maxseq_length, Vector_size))\n",
    "    for i in range(Batch_size):\n",
    "        zero_pad[i, :np.shape(train_batch_X[i])[0], :np.shape(train_batch_X[i])[1] ] = train_batch_X[i]\n",
    "    return zero_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n",
      "28000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "tokens = np.array(token)\n",
    "data_x = tokens[:,0]\n",
    "data_y = tokens[:,1]\n",
    "\n",
    "\n",
    "data_y = One_hot(data_y)\n",
    "data_x = Convert2Vec(embedding, data_x)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x,data_y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(test_x))\n",
    "#train_x = train_x.reset_index(drop=True)\n",
    "#train_y = train_y.reset_index(drop=True)\n",
    "#test_x = test_x.reset_index(drop=True)\n",
    "#test_y = test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x000001C9C17BB588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Start training!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "Batch_size = 32\n",
    "Total_size = len(train_x)\n",
    "Vector_size = 300\n",
    "seq_length = [len(x) for x in train_x]\n",
    "Maxseq_length = max(seq_length)\n",
    "learning_rate = 0.001\n",
    "lstm_units = 128\n",
    "num_class = 5\n",
    "training_epochs = 5\n",
    "keep_prob = 0.75\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, Maxseq_length, Vector_size])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, num_class])\n",
    "seq_len = tf.placeholder(tf.int32 , shape = [None])\n",
    "\n",
    "BiLSTM = Bi_LSTM(lstm_units, num_class, keep_prob)\n",
    "with tf.variable_scope('loss', reuse = tf.AUTO_REUSE) :\n",
    "    logits = BiLSTM.logits(X, BiLSTM.W, BiLSTM.b, seq_len)\n",
    "    loss, optimizer, merged = BiLSTM.model_build(logits, Y, learning_rate)\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "total_batch = int(Total_size / Batch_size)\n",
    "\n",
    "print(\"Start training!\")\n",
    "\n",
    "#modelName = \"BiLSTM.model\"\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>부모 학대 못 이긴 우크라이나 8세 소년 극단적 선택</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NHK 미사일 오보에전문가들 오보로 전쟁 날 수도</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>바른미래 퇴진파 권은희 최고위원직 박탈이유는 당비 미납</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가족사진같은  국무위 단체사진김영철 중앙배치 눈길</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>진주 한 아파트서 방화살인사건주민 5명 숨지고 5명 중경상 등</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>르포 고양 창릉 서울서 15분 욕망의 논밭 들썩</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>카페 점령한 카공족 더 속상한 건 이겁니다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>제네시스 GV80 30 디젤 출시6580만원부터</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>박용만 일본도 보고 있는데최선 다해 대통령 도울 때</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>동생은 이승 형은 저승 관장그럼 저승이 더 좋다는 뜻</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      news  label\n",
       "0            부모 학대 못 이긴 우크라이나 8세 소년 극단적 선택      2\n",
       "1              NHK 미사일 오보에전문가들 오보로 전쟁 날 수도      2\n",
       "2           바른미래 퇴진파 권은희 최고위원직 박탈이유는 당비 미납      3\n",
       "3              가족사진같은  국무위 단체사진김영철 중앙배치 눈길      3\n",
       "4      진주 한 아파트서 방화살인사건주민 5명 숨지고 5명 중경상 등       4\n",
       "...                                    ...    ...\n",
       "11995           르포 고양 창릉 서울서 15분 욕망의 논밭 들썩      5\n",
       "11996              카페 점령한 카공족 더 속상한 건 이겁니다      1\n",
       "11997           제네시스 GV80 30 디젤 출시6580만원부터      1\n",
       "11998         박용만 일본도 보고 있는데최선 다해 대통령 도울 때      5\n",
       "11999        동생은 이승 형은 저승 관장그럼 저승이 더 좋다는 뜻      1\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              부모 학대 못 이긴 우크라이나 8세 소년 극단적 선택\n",
      "1                NHK 미사일 오보에전문가들 오보로 전쟁 날 수도\n",
      "2             바른미래 퇴진파 권은희 최고위원직 박탈이유는 당비 미납\n",
      "3                가족사진같은  국무위 단체사진김영철 중앙배치 눈길\n",
      "4        진주 한 아파트서 방화살인사건주민 5명 숨지고 5명 중경상 등 \n",
      "                        ...                 \n",
      "11995             르포 고양 창릉 서울서 15분 욕망의 논밭 들썩\n",
      "11996                카페 점령한 카공족 더 속상한 건 이겁니다\n",
      "11997             제네시스 GV80 30 디젤 출시6580만원부터\n",
      "11998           박용만 일본도 보고 있는데최선 다해 대통령 도울 때\n",
      "11999          동생은 이승 형은 저승 관장그럼 저승이 더 좋다는 뜻\n",
      "Name: news, Length: 12000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['갤럭시/Noun',\n",
       " '폴드/Noun',\n",
       " '불량/Noun',\n",
       " '강화유리/Noun',\n",
       " '떼다/Verb',\n",
       " '고장/Noun',\n",
       " '나다/Verb',\n",
       " '떼쓰다/Verb',\n",
       " '격/Noun']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_set['news'])\n",
    "tokens[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 01 step : 0875 loss = 0.975620 accuracy= 0.625000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "result  = []\n",
    "loss_graph = []\n",
    "loss_graph_test=[]\n",
    "with tf.Session() as sess:\n",
    "    #writer = tf.summary.FileWriter('', sess.graph)\n",
    "    start_time = time.time()\n",
    "    sess.run(init)\n",
    "    train_writer = tf.summary.FileWriter('Bidirectional_LSTM', sess.graph)\n",
    "    i = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        #try :\n",
    "            avg_acc, avg_loss = 0. , 0.\n",
    "            for step in range(total_batch):\n",
    "\n",
    "                train_batch_X = train_x[step*Batch_size : step*Batch_size+Batch_size]\n",
    "\n",
    "                train_batch_Y = train_y[step*Batch_size : step*Batch_size+Batch_size]\n",
    "                batch_seq_length = seq_length[step*Batch_size : step*Batch_size+Batch_size]\n",
    "                train_batch_X = Zero_padding(train_batch_X, Batch_size, Maxseq_length, Vector_size)\n",
    "                \n",
    "                #summary, _ = sess.run([merged,optimizer], feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length})\n",
    "\n",
    "                sess.run(optimizer, feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length})\n",
    "                \n",
    "                loss_ = sess.run(loss, feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length})\n",
    "                avg_loss += loss_ / total_batch\n",
    "\n",
    "                acc = sess.run(accuracy , feed_dict={X: train_batch_X, Y: train_batch_Y, seq_len: batch_seq_length})\n",
    "                avg_acc += acc / total_batch\n",
    "                #train_writer.add_summary(summary, step)\n",
    "            print(\"epoch : {:02d} step : {:04d} loss = {:.6f} accuracy= {:.6f}\".format(epoch+1, step+1, loss_, acc))\n",
    "            #print(\"Test Accuracy : \", sess.run(accuracy, feed_dict={X:test_x, Y:test_y}))\n",
    "            #summary = sess.run(BiLSTM.graph_build(avg_loss, avg_acc))       \n",
    "            #train_writer.add_summary(summary, i)\n",
    "            #merged = BiLSTM.graph_build()\n",
    "            i += 1\n",
    "        #except : \n",
    "            #print('Error Epoch : ', epoch)\n",
    "            loss_graph.append([acc,epoch])\n",
    "            #acc = sess.run(accuracy , feed_dict={X: test_x, Y: test_y, seq_len: batch_seq_length})\n",
    "            #print('Test Accuracy : ', acc)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    minute = int(duration / 60)\n",
    "    second = int(duration) % 60\n",
    "    print(\"%dminutes %dseconds\" % (minute,second))\n",
    "    save_path = saver.save(sess, os.getcwd())\n",
    "\n",
    "    train_writer.close()\n",
    "    print('save_path',save_path)\n",
    "    \n",
    "    test_size = len(test_x)\n",
    "    test_batch = int(test_size / Batch_size)\n",
    "    seq_length = [len(x) for x in test_x]\n",
    "    keep_prob = 1.0\n",
    "    total_acc = 0\n",
    "    for step in range(test_batch):\n",
    "        test_batch_X = test_x[step*Batch_size: step*Batch_size + Batch_size]\n",
    "        test_batch_Y = test_y[step*Batch_size: step*Batch_size + Batch_size]\n",
    "        batch_seq_length = seq_length[step*Batch_size : step*Batch_size + Batch_size]\n",
    "        test_batch_X = Zero_padding(test_batch_X, Batch_size, Maxseq_length, Vector_size)\n",
    "        \n",
    "        #summary, _ = sess.run([mreged, optimizer], feed_dict = {X: test_batch_X, Y: test_batch_Y, seq_len: batch_seq_length})\n",
    "        acc = sess.run(accuracy , feed_dict={X: test_batch_X, Y: test_batch_Y, seq_len: batch_seq_length})\n",
    "        total_acc += acc/test_batch\n",
    "        pred_v = sess.run(prediction , feed_dict={X: test_batch_X, Y: test_batch_Y, seq_len: batch_seq_length})\n",
    " \n",
    "        print(\"loss = {:.6f} accuracy = {:.6f}\".format(loss_, acc), \"/ step =\",step)\n",
    "            \n",
    "            \n",
    "    print(\" Total Accuracy : {}\".format(total_acc))\n",
    "    result.append(total_acc)\n",
    "\n",
    "    \n",
    "print(\"----------------------------------------\")\n",
    "print(\"BI-LSTM finish\")\n",
    "for i in range(0, len(result)):\n",
    "    print(\"epoch : \", i+1, \" / accuracy : \", result[i])\n",
    "    \n",
    "print(\"\\nBest Result epoch : \", result.index(max(result)) + 1, \" / accuracy: \", max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
