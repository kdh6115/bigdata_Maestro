{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 기초(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 : 텐서를 흘려보내면서 머신러닝과 딥러닝 알고리즘을 수행하는 라이브러리\n",
    "- 숫자 1 (스칼라 or rank0 텐서)\n",
    "- 1차원 배열 (벡터 or rank1 텐서)\n",
    "- 2차원 배열 (행렬 or rank2 텐서)\n",
    "- 3차원 배열 (텐서 or rank3 텐서)\n",
    "\n",
    "텐서들은 그래프 구조에서 노드에서 노드로 흘러감\n",
    "세션을 만들고 세션을 통해 노드간의 데이터(텐서) 연산 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(2, 2), dtype=float32)\n",
      "[1.0, 2.0]\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "[3.0]\n",
      "[[2. 3.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 상수 노드 정의\n",
    "a = tf.constant(1.0, name = 'a') \n",
    "b = tf.constant(2.0, name = 'b')\n",
    "c = tf.constant([ [1.0, 2.0], [3.0, 4.0] ])\n",
    "\n",
    "# 노드의 상태 출력\n",
    "print(a); print(a+b); print(c)\n",
    "\n",
    "# 세션을 만들고 노드간의 텐서 연산 실행\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run([a, b]))\n",
    "print(sess.run(c))\n",
    "print(sess.run([a+b]))\n",
    "print(sess.run(c+1.0)) # broadcast 수행\n",
    "\n",
    "# 세션 close\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "[4. 6.]\n",
      "400.0\n",
      "[400. 600.]\n"
     ]
    }
   ],
   "source": [
    "# 플레이스홀더 노드 정의 (임의의 값을 입력받기 위해)\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = a+b\n",
    "\n",
    "# 세션을 만들고 플레이스홀더 노드를 통해 값 입력받음\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(c, feed_dict = {a:1.0, b:3.0}))\n",
    "print(sess.run(c, feed_dict = {a:[1.0, 2.0], b:[3.0, 4.0]}))\n",
    "\n",
    "# 연산추가\n",
    "d = 100 * c\n",
    "\n",
    "print(sess.run(d, feed_dict = {a:1.0, b:3.0}))\n",
    "print(sess.run(d, feed_dict = {a:[1.0, 2.0], b:[3.0, 4.0]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# placeholder 노드는 머시러닝/딥러닝에서 입력데이터, 정답데이터를 넣어주기 위한 용도로 주로 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , W1 =  [-0.14917932] , b1 =  [2.730621]\n",
      "step =  0 , W2 =  [[0.0660696 1.835704 ]] , b2 =  [[-0.05446811  1.1360923 ]]\n",
      "step =  1 , W1 =  [-1.1491793] , b1 =  [1.7306211]\n",
      "step =  1 , W2 =  [[-0.9339304   0.83570397]] , b2 =  [[-1.0544682  0.1360923]]\n",
      "step =  2 , W1 =  [-3.1491795] , b1 =  [-0.2693789]\n",
      "step =  2 , W2 =  [[-2.9339304 -1.164296 ]] , b2 =  [[-3.0544682 -1.8639077]]\n"
     ]
    }
   ],
   "source": [
    "# 가중치나 바이어스처럼 값이 계속 업데이트되는 변수노드 정의\n",
    "W1 = tf.Variable(tf.random_normal([1])) # np.random.rand(1) 비슷함\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1,2]))\n",
    "b2 = tf.Variable(tf.random_normal([1,2]))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3) :\n",
    "    W1 = W1 - step   # W1 변수노드 업데이트\n",
    "    b1 = b1 - step\n",
    "    \n",
    "    W2 = W2- step\n",
    "    b2 = b2 - step\n",
    "    \n",
    "    print(\"step = \", step, \", W1 = \", sess.run(W1), \", b1 = \", sess.run(b1))\n",
    "    print(\"step = \", step, \", W2 = \", sess.run(W2), \", b2 = \", sess.run(b2))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 기초(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (multi-variable example)\n",
    "- 입력과 정답데이터로 분리\n",
    "- y = X*W +b = > 손실함수(MSE)가 최소값인가?\n",
    "- 아니라면 W,b를 최적화 하기위해 GDA(경사하강법-미분)을 이용하여 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (25, 3)\n",
      "t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data-01.csv', delimiter=',') # 25x4\n",
    "\n",
    "x_data = loaded_data[:, 0:-1] # 25X3\n",
    "t_data = loaded_data[:, [-1]] # 25X1\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 1])) # 3X1\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 3]) # None대신 25써도 됨, None이라 쓴 이유는 차후에 확장하기 위해서\n",
    "T = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(X, W) # 현재 X, W, b를 바탕으로 계산된 값\n",
    "loss = tf.reduce_mean(tf.square(y-T)) # MSE 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  90396.66\n",
      "step =  400 , loss_val =  7.210976\n",
      "step =  800 , loss_val =  6.9096007\n",
      "step =  1200 , loss_val =  6.692799\n",
      "step =  1600 , loss_val =  6.5362945\n",
      "step =  2000 , loss_val =  6.422879\n",
      "step =  2400 , loss_val =  6.3403063\n",
      "step =  2800 , loss_val =  6.279939\n",
      "step =  3200 , loss_val =  6.2355404\n",
      "step =  3600 , loss_val =  6.2027583\n",
      "step =  4000 , loss_val =  6.1783843\n",
      "step =  4400 , loss_val =  6.1601744\n",
      "step =  4800 , loss_val =  6.1464806\n",
      "step =  5200 , loss_val =  6.1361384\n",
      "step =  5600 , loss_val =  6.1282454\n",
      "step =  6000 , loss_val =  6.122215\n",
      "step =  6400 , loss_val =  6.117565\n",
      "step =  6800 , loss_val =  6.113972\n",
      "step =  7200 , loss_val =  6.1111627\n",
      "step =  7600 , loss_val =  6.108971\n",
      "step =  8000 , loss_val =  6.1072392\n",
      "\n",
      "Prediction is  [[179.15967]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(8001) :\n",
    "        loss_val, y_val, _ = sess.run([loss, y, train], feed_dict = {X:x_data, T:t_data}) # feed_dict를 통해 입력데이터와 정답데이터 입력\n",
    "        # _ : 저장할 이유는 없지만 로테이션을 맞추기 위해\n",
    "        if step % 400 == 0 :\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "    \n",
    "    print(\"\\nPrediction is \", sess.run(y, feed_dict={X:[[100, 98, 81]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 기초(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "- 입력, 정답데이터 분리\n",
    "- z = X*W+b => sigmoid(z) = y\n",
    "- 손실함수가 최소인가\n",
    "- 아니라면 GDA를 통해 W,b를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded_data =  (759, 9)\n",
      "x_data =  (759, 8) \n",
      "t_data =  (759, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./diabetes.csv', delimiter = ',')  # 759x9\n",
    "\n",
    "x_data = loaded_data[:, 0:-1]\n",
    "t_data = loaded_data[:,[-1]]\n",
    "\n",
    "print(\"loaded_data = \", loaded_data.shape)\n",
    "print(\"x_data = \", x_data.shape, \"\\nt_data = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 8])\n",
    "T = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.matmul(X, W) + b # 선형회귀 값 z\n",
    "\n",
    "y = tf.sigmoid(z)       # 시그모이도로 계산값\n",
    "\n",
    "# 손실함수는 Cross-Entropy\n",
    "loss = -tf.reduce_mean(T*tf.log(y + (1-T)*tf.log(1-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(y>0.5, dtype = tf.float32) # 759개 데이터와 비교 y>0.5이면 True 아니면 False\n",
    "                                               # tf.cast를 통해 True는 1 False는 0으로 리턴\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, T), dtype = tf.float32)) # predicted와 T가 같으면 True 아니면 False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  nan\n",
      "step =  500 , loss_val =  nan\n",
      "step =  1000 , loss_val =  nan\n",
      "step =  1500 , loss_val =  nan\n",
      "step =  2000 , loss_val =  nan\n",
      "step =  2500 , loss_val =  nan\n",
      "step =  3000 , loss_val =  nan\n",
      "step =  3500 , loss_val =  nan\n",
      "step =  4000 , loss_val =  nan\n",
      "step =  4500 , loss_val =  nan\n",
      "step =  5000 , loss_val =  nan\n",
      "step =  5500 , loss_val =  nan\n",
      "step =  6000 , loss_val =  nan\n",
      "step =  6500 , loss_val =  nan\n",
      "step =  7000 , loss_val =  nan\n",
      "step =  7500 , loss_val =  nan\n",
      "step =  8000 , loss_val =  nan\n",
      "step =  8500 , loss_val =  nan\n",
      "step =  9000 , loss_val =  nan\n",
      "step =  9500 , loss_val =  nan\n",
      "step =  10000 , loss_val =  nan\n",
      "step =  10500 , loss_val =  nan\n",
      "step =  11000 , loss_val =  nan\n",
      "step =  11500 , loss_val =  nan\n",
      "step =  12000 , loss_val =  nan\n",
      "step =  12500 , loss_val =  nan\n",
      "step =  13000 , loss_val =  nan\n",
      "step =  13500 , loss_val =  nan\n",
      "step =  14000 , loss_val =  nan\n",
      "step =  14500 , loss_val =  nan\n",
      "step =  15000 , loss_val =  nan\n",
      "step =  15500 , loss_val =  nan\n",
      "step =  16000 , loss_val =  nan\n",
      "step =  16500 , loss_val =  nan\n",
      "step =  17000 , loss_val =  nan\n",
      "step =  17500 , loss_val =  nan\n",
      "step =  18000 , loss_val =  nan\n",
      "step =  18500 , loss_val =  nan\n",
      "step =  19000 , loss_val =  nan\n",
      "step =  19500 , loss_val =  nan\n",
      "step =  20000 , loss_val =  nan\n",
      "\n",
      "y_val.shape = (759, 1) , predicted_val (759, 1)\n",
      "\n",
      "Accuracy =  0.65349144\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for step in range(20001) :\n",
    "        loss_val, _ = sess.run([loss, train], feed_dict = {X:x_data, T:t_data})\n",
    "        if step % 500 == 0:\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "            \n",
    "    # Accuracy 확인\n",
    "    y_val, predicted_val, accuracy_val = sess.run([y, predicted, accuracy], feed_dict = {X:x_data, T:t_data})\n",
    "    \n",
    "    print(\"\\ny_val.shape =\", y_val.shape, \", predicted_val\", predicted_val.shape)\n",
    "    print(\"\\nAccuracy = \", accuracy_val) \n",
    "    # 하이퍼 파라미터 조정, 가중치 초기화 방법 변경 또는 아키텍쳐 변경 등을 통해 정확도 높일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 기초(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images)) # 55000, 784(784 픽셀을 가진 이미지 55000개)\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))   # 55000, 10 (10개 원핫인코딩을 가진 55000개)\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "batch_size = 100   # 한번에 입력으로 주어지는 MNIST 개수\n",
    "\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100 # 임의로 설정\n",
    "output_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "T = tf.placeholder(tf.float32, [None, output_nodes])\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes])) # 은닉층 가중치 노드\n",
    "b2 = tf.Variable(tf.random_normal([hidden_nodes]))              # 은닉층 바이어스 노드\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))# 출력층 가중치 노드\n",
    "b3 = tf.Variable(tf.random_normal([output_nodes]))              # 출력층 바이어스 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = tf.matmul(X, W2) + b2  # 선형회귀 선형회귀 값 Z2\n",
    "A2 = tf.nn.relu(Z2) # 은닉층 출력 값 A2, sigmoid 대신 사용\n",
    "\n",
    "# 출력층 선형회귀 값 Z3, 즉 softmax에 들어가는 입력값\n",
    "Z3 = logits = tf.matmul(A2, W3) + b3\n",
    "\n",
    "y = A3 = tf.nn.softmax(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 선형회귀 값(logits) Z3와 정답 T를 이용하여 손실함수 크로스 엔트로피 계산\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=T))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대한 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T,1)) #tf.argmax(A3, 1) 1은 행\n",
    "\n",
    "# batch_size X 10의 True, False를 1 또는 0으로 변환(tf.cast)\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  85.47342\n",
      "step =  100 , loss_val =  4.66308\n",
      "step =  200 , loss_val =  2.03977\n",
      "step =  300 , loss_val =  2.923041\n",
      "step =  400 , loss_val =  1.6499202\n",
      "step =  500 , loss_val =  1.7070236\n",
      "step =  0 , loss_val =  0.7944725\n",
      "step =  100 , loss_val =  0.8444023\n",
      "step =  200 , loss_val =  1.40542\n",
      "step =  300 , loss_val =  1.2733067\n",
      "step =  400 , loss_val =  0.81509805\n",
      "step =  500 , loss_val =  0.76210624\n",
      "step =  0 , loss_val =  1.7060696\n",
      "step =  100 , loss_val =  0.22344132\n",
      "step =  200 , loss_val =  0.974605\n",
      "step =  300 , loss_val =  0.90305984\n",
      "step =  400 , loss_val =  0.42978066\n",
      "step =  500 , loss_val =  1.3534541\n",
      "step =  0 , loss_val =  0.32209054\n",
      "step =  100 , loss_val =  0.8654674\n",
      "step =  200 , loss_val =  0.72328436\n",
      "step =  300 , loss_val =  0.37409386\n",
      "step =  400 , loss_val =  0.7021297\n",
      "step =  500 , loss_val =  0.6836505\n",
      "step =  0 , loss_val =  0.3708986\n",
      "step =  100 , loss_val =  0.68478477\n",
      "step =  200 , loss_val =  0.2962578\n",
      "step =  300 , loss_val =  0.5394558\n",
      "step =  400 , loss_val =  0.46296898\n",
      "step =  500 , loss_val =  0.4468934\n",
      "step =  0 , loss_val =  0.35177583\n",
      "step =  100 , loss_val =  0.2249871\n",
      "step =  200 , loss_val =  0.40284446\n",
      "step =  300 , loss_val =  0.5257027\n",
      "step =  400 , loss_val =  0.30725774\n",
      "step =  500 , loss_val =  0.46484527\n",
      "step =  0 , loss_val =  0.35858956\n",
      "step =  100 , loss_val =  0.3530223\n",
      "step =  200 , loss_val =  0.4095553\n",
      "step =  300 , loss_val =  0.2924006\n",
      "step =  400 , loss_val =  0.3688017\n",
      "step =  500 , loss_val =  0.5707784\n",
      "step =  0 , loss_val =  0.3372551\n",
      "step =  100 , loss_val =  0.24896461\n",
      "step =  200 , loss_val =  0.20391265\n",
      "step =  300 , loss_val =  0.21680933\n",
      "step =  400 , loss_val =  0.33446252\n",
      "step =  500 , loss_val =  0.28496236\n",
      "step =  0 , loss_val =  0.2533499\n",
      "step =  100 , loss_val =  0.31375372\n",
      "step =  200 , loss_val =  0.17496318\n",
      "step =  300 , loss_val =  0.11886768\n",
      "step =  400 , loss_val =  0.3915714\n",
      "step =  500 , loss_val =  0.40920097\n",
      "step =  0 , loss_val =  0.16591688\n",
      "step =  100 , loss_val =  0.32066995\n",
      "step =  200 , loss_val =  0.17954412\n",
      "step =  300 , loss_val =  0.20988396\n",
      "step =  400 , loss_val =  0.37400168\n",
      "step =  500 , loss_val =  0.26142868\n",
      "step =  0 , loss_val =  0.057175074\n",
      "step =  100 , loss_val =  0.28240025\n",
      "step =  200 , loss_val =  0.18782024\n",
      "step =  300 , loss_val =  0.27336255\n",
      "step =  400 , loss_val =  0.36734337\n",
      "step =  500 , loss_val =  0.3848385\n",
      "step =  0 , loss_val =  0.4429087\n",
      "step =  100 , loss_val =  0.24020286\n",
      "step =  200 , loss_val =  0.18114279\n",
      "step =  300 , loss_val =  0.20754221\n",
      "step =  400 , loss_val =  0.326074\n",
      "step =  500 , loss_val =  0.26094234\n",
      "step =  0 , loss_val =  0.40250313\n",
      "step =  100 , loss_val =  0.2691201\n",
      "step =  200 , loss_val =  0.35647777\n",
      "step =  300 , loss_val =  0.28893188\n",
      "step =  400 , loss_val =  0.1894433\n",
      "step =  500 , loss_val =  0.25336158\n",
      "step =  0 , loss_val =  0.17735104\n",
      "step =  100 , loss_val =  0.22355293\n",
      "step =  200 , loss_val =  0.28139183\n",
      "step =  300 , loss_val =  0.3273835\n",
      "step =  400 , loss_val =  0.18717372\n",
      "step =  500 , loss_val =  0.17608872\n",
      "step =  0 , loss_val =  0.0789879\n",
      "step =  100 , loss_val =  0.24553856\n",
      "step =  200 , loss_val =  0.23169659\n",
      "step =  300 , loss_val =  0.23246674\n",
      "step =  400 , loss_val =  0.24765491\n",
      "step =  500 , loss_val =  0.31764963\n",
      "step =  0 , loss_val =  0.17442459\n",
      "step =  100 , loss_val =  0.19635509\n",
      "step =  200 , loss_val =  0.2021295\n",
      "step =  300 , loss_val =  0.5250217\n",
      "step =  400 , loss_val =  0.25800365\n",
      "step =  500 , loss_val =  0.22006293\n",
      "step =  0 , loss_val =  0.13830557\n",
      "step =  100 , loss_val =  0.28084487\n",
      "step =  200 , loss_val =  0.113633536\n",
      "step =  300 , loss_val =  0.21055523\n",
      "step =  400 , loss_val =  0.34733278\n",
      "step =  500 , loss_val =  0.16639262\n",
      "step =  0 , loss_val =  0.15088297\n",
      "step =  100 , loss_val =  0.35198215\n",
      "step =  200 , loss_val =  0.25299218\n",
      "step =  300 , loss_val =  0.18022186\n",
      "step =  400 , loss_val =  0.1634652\n",
      "step =  500 , loss_val =  0.22918117\n",
      "step =  0 , loss_val =  0.31210098\n",
      "step =  100 , loss_val =  0.2813089\n",
      "step =  200 , loss_val =  0.16362244\n",
      "step =  300 , loss_val =  0.33114287\n",
      "step =  400 , loss_val =  0.11472582\n",
      "step =  500 , loss_val =  0.1359874\n",
      "step =  0 , loss_val =  0.35012856\n",
      "step =  100 , loss_val =  0.102900654\n",
      "step =  200 , loss_val =  0.3291645\n",
      "step =  300 , loss_val =  0.20616016\n",
      "step =  400 , loss_val =  0.24731165\n",
      "step =  500 , loss_val =  0.12279452\n",
      "step =  0 , loss_val =  0.10824674\n",
      "step =  100 , loss_val =  0.2342244\n",
      "step =  200 , loss_val =  0.21205993\n",
      "step =  300 , loss_val =  0.24459255\n",
      "step =  400 , loss_val =  0.157778\n",
      "step =  500 , loss_val =  0.108021826\n",
      "step =  0 , loss_val =  0.14029044\n",
      "step =  100 , loss_val =  0.19081707\n",
      "step =  200 , loss_val =  0.21458986\n",
      "step =  300 , loss_val =  0.16557877\n",
      "step =  400 , loss_val =  0.08183971\n",
      "step =  500 , loss_val =  0.3932456\n",
      "step =  0 , loss_val =  0.18031937\n",
      "step =  100 , loss_val =  0.16540793\n",
      "step =  200 , loss_val =  0.24453613\n",
      "step =  300 , loss_val =  0.357547\n",
      "step =  400 , loss_val =  0.15448473\n",
      "step =  500 , loss_val =  0.2463236\n",
      "step =  0 , loss_val =  0.17735252\n",
      "step =  100 , loss_val =  0.26481304\n",
      "step =  200 , loss_val =  0.3369458\n",
      "step =  300 , loss_val =  0.18327753\n",
      "step =  400 , loss_val =  0.23548332\n",
      "step =  500 , loss_val =  0.13236111\n",
      "step =  0 , loss_val =  0.27323493\n",
      "step =  100 , loss_val =  0.41177338\n",
      "step =  200 , loss_val =  0.24334617\n",
      "step =  300 , loss_val =  0.2900298\n",
      "step =  400 , loss_val =  0.37127358\n",
      "step =  500 , loss_val =  0.16204938\n",
      "step =  0 , loss_val =  0.18720171\n",
      "step =  100 , loss_val =  0.26387373\n",
      "step =  200 , loss_val =  0.20123565\n",
      "step =  300 , loss_val =  0.37310532\n",
      "step =  400 , loss_val =  0.08723766\n",
      "step =  500 , loss_val =  0.20882845\n",
      "step =  0 , loss_val =  0.09303949\n",
      "step =  100 , loss_val =  0.17522003\n",
      "step =  200 , loss_val =  0.11544632\n",
      "step =  300 , loss_val =  0.22439541\n",
      "step =  400 , loss_val =  0.26295924\n",
      "step =  500 , loss_val =  0.095475346\n",
      "step =  0 , loss_val =  0.23713139\n",
      "step =  100 , loss_val =  0.1498604\n",
      "step =  200 , loss_val =  0.12743825\n",
      "step =  300 , loss_val =  0.2776305\n",
      "step =  400 , loss_val =  0.28397712\n",
      "step =  500 , loss_val =  0.07764315\n",
      "step =  0 , loss_val =  0.06189348\n",
      "step =  100 , loss_val =  0.29187983\n",
      "step =  200 , loss_val =  0.118629806\n",
      "step =  300 , loss_val =  0.18874225\n",
      "step =  400 , loss_val =  0.1514594\n",
      "step =  500 , loss_val =  0.24728017\n",
      "step =  0 , loss_val =  0.25183693\n",
      "step =  100 , loss_val =  0.1379186\n",
      "step =  200 , loss_val =  0.07980473\n",
      "step =  300 , loss_val =  0.11896038\n",
      "step =  400 , loss_val =  0.109305695\n",
      "step =  500 , loss_val =  0.045472004\n",
      "step =  0 , loss_val =  0.19575767\n",
      "step =  100 , loss_val =  0.13786982\n",
      "step =  200 , loss_val =  0.1326819\n",
      "step =  300 , loss_val =  0.21666878\n",
      "step =  400 , loss_val =  0.17596264\n",
      "step =  500 , loss_val =  0.25175217\n",
      "step =  0 , loss_val =  0.14543867\n",
      "step =  100 , loss_val =  0.22753258\n",
      "step =  200 , loss_val =  0.3375478\n",
      "step =  300 , loss_val =  0.19297534\n",
      "step =  400 , loss_val =  0.15061645\n",
      "step =  500 , loss_val =  0.14629549\n",
      "step =  0 , loss_val =  0.16384384\n",
      "step =  100 , loss_val =  0.15216863\n",
      "step =  200 , loss_val =  0.23983112\n",
      "step =  300 , loss_val =  0.2574549\n",
      "step =  400 , loss_val =  0.10359402\n",
      "step =  500 , loss_val =  0.14167225\n",
      "step =  0 , loss_val =  0.15199979\n",
      "step =  100 , loss_val =  0.19873127\n",
      "step =  200 , loss_val =  0.18422252\n",
      "step =  300 , loss_val =  0.13412575\n",
      "step =  400 , loss_val =  0.1771376\n",
      "step =  500 , loss_val =  0.084857054\n",
      "step =  0 , loss_val =  0.065458596\n",
      "step =  100 , loss_val =  0.10460303\n",
      "step =  200 , loss_val =  0.059881687\n",
      "step =  300 , loss_val =  0.1889857\n",
      "step =  400 , loss_val =  0.08266868\n",
      "step =  500 , loss_val =  0.24687265\n",
      "step =  0 , loss_val =  0.114025325\n",
      "step =  100 , loss_val =  0.11466432\n",
      "step =  200 , loss_val =  0.101887845\n",
      "step =  300 , loss_val =  0.24456677\n",
      "step =  400 , loss_val =  0.15313391\n",
      "step =  500 , loss_val =  0.121278495\n",
      "step =  0 , loss_val =  0.08157896\n",
      "step =  100 , loss_val =  0.22057915\n",
      "step =  200 , loss_val =  0.29740417\n",
      "step =  300 , loss_val =  0.13782354\n",
      "step =  400 , loss_val =  0.25368473\n",
      "step =  500 , loss_val =  0.22938675\n",
      "step =  0 , loss_val =  0.25493723\n",
      "step =  100 , loss_val =  0.09761457\n",
      "step =  200 , loss_val =  0.26568782\n",
      "step =  300 , loss_val =  0.2141574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  400 , loss_val =  0.19914627\n",
      "step =  500 , loss_val =  0.5116045\n",
      "step =  0 , loss_val =  0.14650555\n",
      "step =  100 , loss_val =  0.1750741\n",
      "step =  200 , loss_val =  0.15245241\n",
      "step =  300 , loss_val =  0.3672428\n",
      "step =  400 , loss_val =  0.11178449\n",
      "step =  500 , loss_val =  0.1691236\n",
      "step =  0 , loss_val =  0.23289658\n",
      "step =  100 , loss_val =  0.12346192\n",
      "step =  200 , loss_val =  0.08923296\n",
      "step =  300 , loss_val =  0.30790415\n",
      "step =  400 , loss_val =  0.25293347\n",
      "step =  500 , loss_val =  0.09012916\n",
      "step =  0 , loss_val =  0.21697105\n",
      "step =  100 , loss_val =  0.28342074\n",
      "step =  200 , loss_val =  0.07491186\n",
      "step =  300 , loss_val =  0.23760095\n",
      "step =  400 , loss_val =  0.25587463\n",
      "step =  500 , loss_val =  0.15526254\n",
      "step =  0 , loss_val =  0.16169089\n",
      "step =  100 , loss_val =  0.039699048\n",
      "step =  200 , loss_val =  0.06306884\n",
      "step =  300 , loss_val =  0.06981277\n",
      "step =  400 , loss_val =  0.0487541\n",
      "step =  500 , loss_val =  0.055874325\n",
      "step =  0 , loss_val =  0.0996742\n",
      "step =  100 , loss_val =  0.19571786\n",
      "step =  200 , loss_val =  0.13365689\n",
      "step =  300 , loss_val =  0.20079227\n",
      "step =  400 , loss_val =  0.11713463\n",
      "step =  500 , loss_val =  0.11433176\n",
      "step =  0 , loss_val =  0.17463106\n",
      "step =  100 , loss_val =  0.11027819\n",
      "step =  200 , loss_val =  0.09558565\n",
      "step =  300 , loss_val =  0.09287476\n",
      "step =  400 , loss_val =  0.14534615\n",
      "step =  500 , loss_val =  0.23497528\n",
      "step =  0 , loss_val =  0.14419986\n",
      "step =  100 , loss_val =  0.08497899\n",
      "step =  200 , loss_val =  0.08960615\n",
      "step =  300 , loss_val =  0.23752773\n",
      "step =  400 , loss_val =  0.17956446\n",
      "step =  500 , loss_val =  0.10512624\n",
      "step =  0 , loss_val =  0.13221066\n",
      "step =  100 , loss_val =  0.1720305\n",
      "step =  200 , loss_val =  0.20179728\n",
      "step =  300 , loss_val =  0.17869641\n",
      "step =  400 , loss_val =  0.22306958\n",
      "step =  500 , loss_val =  0.16340107\n",
      "step =  0 , loss_val =  0.20251556\n",
      "step =  100 , loss_val =  0.08850481\n",
      "step =  200 , loss_val =  0.25893125\n",
      "step =  300 , loss_val =  0.16741242\n",
      "step =  400 , loss_val =  0.105858214\n",
      "step =  500 , loss_val =  0.07674545\n",
      "step =  0 , loss_val =  0.10727057\n",
      "step =  100 , loss_val =  0.07585318\n",
      "step =  200 , loss_val =  0.25625905\n",
      "step =  300 , loss_val =  0.15550089\n",
      "step =  400 , loss_val =  0.22654717\n",
      "step =  500 , loss_val =  0.09102788\n",
      "step =  0 , loss_val =  0.056800507\n",
      "step =  100 , loss_val =  0.13839415\n",
      "step =  200 , loss_val =  0.13791841\n",
      "step =  300 , loss_val =  0.18216492\n",
      "step =  400 , loss_val =  0.053105727\n",
      "step =  500 , loss_val =  0.11324882\n",
      "step =  0 , loss_val =  0.18928505\n",
      "step =  100 , loss_val =  0.15587217\n",
      "step =  200 , loss_val =  0.12480551\n",
      "step =  300 , loss_val =  0.10692971\n",
      "step =  400 , loss_val =  0.14097904\n",
      "step =  500 , loss_val =  0.12353116\n",
      "step =  0 , loss_val =  0.10536547\n",
      "step =  100 , loss_val =  0.1168497\n",
      "step =  200 , loss_val =  0.11003993\n",
      "step =  300 , loss_val =  0.07233987\n",
      "step =  400 , loss_val =  0.056317445\n",
      "step =  500 , loss_val =  0.14028919\n",
      "step =  0 , loss_val =  0.16154507\n",
      "step =  100 , loss_val =  0.14369561\n",
      "step =  200 , loss_val =  0.0671287\n",
      "step =  300 , loss_val =  0.0772732\n",
      "step =  400 , loss_val =  0.097810075\n",
      "step =  500 , loss_val =  0.10399019\n",
      "step =  0 , loss_val =  0.15511101\n",
      "step =  100 , loss_val =  0.22098707\n",
      "step =  200 , loss_val =  0.070469014\n",
      "step =  300 , loss_val =  0.14510457\n",
      "step =  400 , loss_val =  0.11899933\n",
      "step =  500 , loss_val =  0.16726848\n",
      "step =  0 , loss_val =  0.11541647\n",
      "step =  100 , loss_val =  0.21290737\n",
      "step =  200 , loss_val =  0.12162327\n",
      "step =  300 , loss_val =  0.09109194\n",
      "step =  400 , loss_val =  0.16579048\n",
      "step =  500 , loss_val =  0.13784774\n",
      "step =  0 , loss_val =  0.06940284\n",
      "step =  100 , loss_val =  0.07877581\n",
      "step =  200 , loss_val =  0.061046515\n",
      "step =  300 , loss_val =  0.12426649\n",
      "step =  400 , loss_val =  0.15931238\n",
      "step =  500 , loss_val =  0.122108735\n",
      "step =  0 , loss_val =  0.09439742\n",
      "step =  100 , loss_val =  0.16087483\n",
      "step =  200 , loss_val =  0.31910288\n",
      "step =  300 , loss_val =  0.27879897\n",
      "step =  400 , loss_val =  0.19314033\n",
      "step =  500 , loss_val =  0.098128036\n",
      "step =  0 , loss_val =  0.046821564\n",
      "step =  100 , loss_val =  0.06869057\n",
      "step =  200 , loss_val =  0.058067285\n",
      "step =  300 , loss_val =  0.19341828\n",
      "step =  400 , loss_val =  0.096187524\n",
      "step =  500 , loss_val =  0.1705124\n",
      "step =  0 , loss_val =  0.12915827\n",
      "step =  100 , loss_val =  0.3207981\n",
      "step =  200 , loss_val =  0.13063048\n",
      "step =  300 , loss_val =  0.04098681\n",
      "step =  400 , loss_val =  0.04842065\n",
      "step =  500 , loss_val =  0.083237745\n",
      "step =  0 , loss_val =  0.034006745\n",
      "step =  100 , loss_val =  0.10951803\n",
      "step =  200 , loss_val =  0.11696117\n",
      "step =  300 , loss_val =  0.11544707\n",
      "step =  400 , loss_val =  0.11474334\n",
      "step =  500 , loss_val =  0.11800333\n",
      "step =  0 , loss_val =  0.030280685\n",
      "step =  100 , loss_val =  0.09807012\n",
      "step =  200 , loss_val =  0.1336485\n",
      "step =  300 , loss_val =  0.17509499\n",
      "step =  400 , loss_val =  0.12524083\n",
      "step =  500 , loss_val =  0.026309067\n",
      "step =  0 , loss_val =  0.099188976\n",
      "step =  100 , loss_val =  0.2273138\n",
      "step =  200 , loss_val =  0.08491312\n",
      "step =  300 , loss_val =  0.06287206\n",
      "step =  400 , loss_val =  0.0662772\n",
      "step =  500 , loss_val =  0.13483861\n",
      "step =  0 , loss_val =  0.09294234\n",
      "step =  100 , loss_val =  0.1148444\n",
      "step =  200 , loss_val =  0.14358486\n",
      "step =  300 , loss_val =  0.084645145\n",
      "step =  400 , loss_val =  0.13462208\n",
      "step =  500 , loss_val =  0.18712199\n",
      "step =  0 , loss_val =  0.12509689\n",
      "step =  100 , loss_val =  0.16559124\n",
      "step =  200 , loss_val =  0.24768287\n",
      "step =  300 , loss_val =  0.14455433\n",
      "step =  400 , loss_val =  0.12418947\n",
      "step =  500 , loss_val =  0.210408\n",
      "step =  0 , loss_val =  0.04025428\n",
      "step =  100 , loss_val =  0.111448094\n",
      "step =  200 , loss_val =  0.125704\n",
      "step =  300 , loss_val =  0.14743409\n",
      "step =  400 , loss_val =  0.08271299\n",
      "step =  500 , loss_val =  0.057592984\n",
      "step =  0 , loss_val =  0.089378856\n",
      "step =  100 , loss_val =  0.15837027\n",
      "step =  200 , loss_val =  0.101512335\n",
      "step =  300 , loss_val =  0.14914286\n",
      "step =  400 , loss_val =  0.36297622\n",
      "step =  500 , loss_val =  0.13764209\n",
      "step =  0 , loss_val =  0.10303774\n",
      "step =  100 , loss_val =  0.035313454\n",
      "step =  200 , loss_val =  0.10683335\n",
      "step =  300 , loss_val =  0.1185592\n",
      "step =  400 , loss_val =  0.06439963\n",
      "step =  500 , loss_val =  0.13296248\n",
      "step =  0 , loss_val =  0.1114617\n",
      "step =  100 , loss_val =  0.08095003\n",
      "step =  200 , loss_val =  0.15662256\n",
      "step =  300 , loss_val =  0.1456548\n",
      "step =  400 , loss_val =  0.10869394\n",
      "step =  500 , loss_val =  0.13287081\n",
      "step =  0 , loss_val =  0.060861457\n",
      "step =  100 , loss_val =  0.31280002\n",
      "step =  200 , loss_val =  0.09345343\n",
      "step =  300 , loss_val =  0.0661039\n",
      "step =  400 , loss_val =  0.05849369\n",
      "step =  500 , loss_val =  0.061931267\n",
      "step =  0 , loss_val =  0.09350812\n",
      "step =  100 , loss_val =  0.07698664\n",
      "step =  200 , loss_val =  0.12518677\n",
      "step =  300 , loss_val =  0.19440094\n",
      "step =  400 , loss_val =  0.10761067\n",
      "step =  500 , loss_val =  0.12165941\n",
      "step =  0 , loss_val =  0.06739556\n",
      "step =  100 , loss_val =  0.078813754\n",
      "step =  200 , loss_val =  0.12053481\n",
      "step =  300 , loss_val =  0.1631596\n",
      "step =  400 , loss_val =  0.018181376\n",
      "step =  500 , loss_val =  0.03412125\n",
      "step =  0 , loss_val =  0.14892913\n",
      "step =  100 , loss_val =  0.11183667\n",
      "step =  200 , loss_val =  0.16040087\n",
      "step =  300 , loss_val =  0.14523463\n",
      "step =  400 , loss_val =  0.103416994\n",
      "step =  500 , loss_val =  0.07293061\n",
      "step =  0 , loss_val =  0.1414664\n",
      "step =  100 , loss_val =  0.10453555\n",
      "step =  200 , loss_val =  0.12557992\n",
      "step =  300 , loss_val =  0.1378615\n",
      "step =  400 , loss_val =  0.1715844\n",
      "step =  500 , loss_val =  0.20685367\n",
      "step =  0 , loss_val =  0.097612545\n",
      "step =  100 , loss_val =  0.018193971\n",
      "step =  200 , loss_val =  0.121488206\n",
      "step =  300 , loss_val =  0.027738633\n",
      "step =  400 , loss_val =  0.12383012\n",
      "step =  500 , loss_val =  0.13664088\n",
      "step =  0 , loss_val =  0.07963563\n",
      "step =  100 , loss_val =  0.12492765\n",
      "step =  200 , loss_val =  0.065136\n",
      "step =  300 , loss_val =  0.065901816\n",
      "step =  400 , loss_val =  0.08053664\n",
      "step =  500 , loss_val =  0.12895069\n",
      "step =  0 , loss_val =  0.036011375\n",
      "step =  100 , loss_val =  0.018646516\n",
      "step =  200 , loss_val =  0.09957198\n",
      "step =  300 , loss_val =  0.11617117\n",
      "step =  400 , loss_val =  0.030530358\n",
      "step =  500 , loss_val =  0.15430506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  0.023376765\n",
      "step =  100 , loss_val =  0.119735755\n",
      "step =  200 , loss_val =  0.15679759\n",
      "step =  300 , loss_val =  0.07421705\n",
      "step =  400 , loss_val =  0.06728418\n",
      "step =  500 , loss_val =  0.09589526\n",
      "step =  0 , loss_val =  0.091936156\n",
      "step =  100 , loss_val =  0.063591406\n",
      "step =  200 , loss_val =  0.18193986\n",
      "step =  300 , loss_val =  0.137066\n",
      "step =  400 , loss_val =  0.04279043\n",
      "step =  500 , loss_val =  0.032594875\n",
      "step =  0 , loss_val =  0.084474914\n",
      "step =  100 , loss_val =  0.09915737\n",
      "step =  200 , loss_val =  0.12940568\n",
      "step =  300 , loss_val =  0.06258085\n",
      "step =  400 , loss_val =  0.021686118\n",
      "step =  500 , loss_val =  0.26601666\n",
      "step =  0 , loss_val =  0.0869393\n",
      "step =  100 , loss_val =  0.16252272\n",
      "step =  200 , loss_val =  0.07529534\n",
      "step =  300 , loss_val =  0.08259848\n",
      "step =  400 , loss_val =  0.09263971\n",
      "step =  500 , loss_val =  0.07144951\n",
      "step =  0 , loss_val =  0.10289358\n",
      "step =  100 , loss_val =  0.12493889\n",
      "step =  200 , loss_val =  0.07496108\n",
      "step =  300 , loss_val =  0.10239791\n",
      "step =  400 , loss_val =  0.13908549\n",
      "step =  500 , loss_val =  0.123781964\n",
      "step =  0 , loss_val =  0.0793228\n",
      "step =  100 , loss_val =  0.018268356\n",
      "step =  200 , loss_val =  0.10752116\n",
      "step =  300 , loss_val =  0.10063542\n",
      "step =  400 , loss_val =  0.041447584\n",
      "step =  500 , loss_val =  0.123116314\n",
      "step =  0 , loss_val =  0.1323062\n",
      "step =  100 , loss_val =  0.19698125\n",
      "step =  200 , loss_val =  0.222192\n",
      "step =  300 , loss_val =  0.17004666\n",
      "step =  400 , loss_val =  0.034025088\n",
      "step =  500 , loss_val =  0.07050855\n",
      "step =  0 , loss_val =  0.105618246\n",
      "step =  100 , loss_val =  0.053803097\n",
      "step =  200 , loss_val =  0.16926838\n",
      "step =  300 , loss_val =  0.09141383\n",
      "step =  400 , loss_val =  0.114344604\n",
      "step =  500 , loss_val =  0.109520495\n",
      "step =  0 , loss_val =  0.02363298\n",
      "step =  100 , loss_val =  0.04589409\n",
      "step =  200 , loss_val =  0.12437023\n",
      "step =  300 , loss_val =  0.032130554\n",
      "step =  400 , loss_val =  0.18540062\n",
      "step =  500 , loss_val =  0.17290197\n",
      "step =  0 , loss_val =  0.08483975\n",
      "step =  100 , loss_val =  0.13939951\n",
      "step =  200 , loss_val =  0.059958648\n",
      "step =  300 , loss_val =  0.030699115\n",
      "step =  400 , loss_val =  0.0496225\n",
      "step =  500 , loss_val =  0.11141032\n",
      "step =  0 , loss_val =  0.033816293\n",
      "step =  100 , loss_val =  0.12711692\n",
      "step =  200 , loss_val =  0.088986054\n",
      "step =  300 , loss_val =  0.19954434\n",
      "step =  400 , loss_val =  0.21249108\n",
      "step =  500 , loss_val =  0.16440834\n",
      "step =  0 , loss_val =  0.02453774\n",
      "step =  100 , loss_val =  0.07639563\n",
      "step =  200 , loss_val =  0.11405376\n",
      "step =  300 , loss_val =  0.12072206\n",
      "step =  400 , loss_val =  0.07851536\n",
      "step =  500 , loss_val =  0.061654445\n",
      "step =  0 , loss_val =  0.04050785\n",
      "step =  100 , loss_val =  0.06170891\n",
      "step =  200 , loss_val =  0.09158241\n",
      "step =  300 , loss_val =  0.36534867\n",
      "step =  400 , loss_val =  0.106810495\n",
      "step =  500 , loss_val =  0.05509329\n",
      "step =  0 , loss_val =  0.050210685\n",
      "step =  100 , loss_val =  0.089328974\n",
      "step =  200 , loss_val =  0.055373963\n",
      "step =  300 , loss_val =  0.059132304\n",
      "step =  400 , loss_val =  0.039107904\n",
      "step =  500 , loss_val =  0.05314791\n",
      "step =  0 , loss_val =  0.06337783\n",
      "step =  100 , loss_val =  0.041091684\n",
      "step =  200 , loss_val =  0.054742265\n",
      "step =  300 , loss_val =  0.06585813\n",
      "step =  400 , loss_val =  0.11931314\n",
      "step =  500 , loss_val =  0.115476415\n",
      "step =  0 , loss_val =  0.07657158\n",
      "step =  100 , loss_val =  0.09377622\n",
      "step =  200 , loss_val =  0.030805267\n",
      "step =  300 , loss_val =  0.05521183\n",
      "step =  400 , loss_val =  0.10035465\n",
      "step =  500 , loss_val =  0.065023154\n",
      "step =  0 , loss_val =  0.082711026\n",
      "step =  100 , loss_val =  0.06650808\n",
      "step =  200 , loss_val =  0.0880533\n",
      "step =  300 , loss_val =  0.13966136\n",
      "step =  400 , loss_val =  0.019226098\n",
      "step =  500 , loss_val =  0.05731901\n",
      "step =  0 , loss_val =  0.069790214\n",
      "step =  100 , loss_val =  0.026528137\n",
      "step =  200 , loss_val =  0.044959594\n",
      "step =  300 , loss_val =  0.059070654\n",
      "step =  400 , loss_val =  0.027130777\n",
      "step =  500 , loss_val =  0.099063866\n",
      "step =  0 , loss_val =  0.021567143\n",
      "step =  100 , loss_val =  0.010773625\n",
      "step =  200 , loss_val =  0.056618527\n",
      "step =  300 , loss_val =  0.06038055\n",
      "step =  400 , loss_val =  0.10700331\n",
      "step =  500 , loss_val =  0.13309906\n",
      "step =  0 , loss_val =  0.123402804\n",
      "step =  100 , loss_val =  0.10200651\n",
      "step =  200 , loss_val =  0.1138035\n",
      "step =  300 , loss_val =  0.039848007\n",
      "step =  400 , loss_val =  0.036467887\n",
      "step =  500 , loss_val =  0.105612695\n",
      "step =  0 , loss_val =  0.04862891\n",
      "step =  100 , loss_val =  0.08612499\n",
      "step =  200 , loss_val =  0.06866749\n",
      "step =  300 , loss_val =  0.209991\n",
      "step =  400 , loss_val =  0.03267791\n",
      "step =  500 , loss_val =  0.058780953\n",
      "step =  0 , loss_val =  0.023716504\n",
      "step =  100 , loss_val =  0.041529063\n",
      "step =  200 , loss_val =  0.03003041\n",
      "step =  300 , loss_val =  0.14231598\n",
      "step =  400 , loss_val =  0.10892539\n",
      "step =  500 , loss_val =  0.15007837\n",
      "step =  0 , loss_val =  0.017488515\n",
      "step =  100 , loss_val =  0.15341371\n",
      "step =  200 , loss_val =  0.25588536\n",
      "step =  300 , loss_val =  0.040474653\n",
      "step =  400 , loss_val =  0.10585785\n",
      "step =  500 , loss_val =  0.058271784\n",
      "step =  0 , loss_val =  0.07686594\n",
      "step =  100 , loss_val =  0.09579693\n",
      "step =  200 , loss_val =  0.044768285\n",
      "step =  300 , loss_val =  0.074203305\n",
      "step =  400 , loss_val =  0.022732545\n",
      "step =  500 , loss_val =  0.081184365\n",
      "step =  0 , loss_val =  0.057720955\n",
      "step =  100 , loss_val =  0.09716001\n",
      "step =  200 , loss_val =  0.070931986\n",
      "step =  300 , loss_val =  0.25107569\n",
      "step =  400 , loss_val =  0.063879274\n",
      "step =  500 , loss_val =  0.15478005\n",
      "\n",
      "Accuracy =  0.9477\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epochs) :\n",
    "        total_batch = int(mnist.train.num_examples/batch_size) # 55000/100\n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            loss_val, _ = sess.run([loss, train], feed_dict = {X: batch_x_data, T : batch_t_data})\n",
    "            if step % 100 == 0:\n",
    "                print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "                \n",
    "    test_x_data = mnist.test.images # 10000x784\n",
    "    test_t_data = mnist.test.labels # 10000x10\n",
    "    \n",
    "    accuracy_val = sess.run(accuracy, feed_dict={X : test_x_data, T : test_t_data})\n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    # MNIST와 같은 이미지데이터에 대한 인식정확도를 99%이상으로 높이기 위해서는 신경망 아키텍처를 CNN으로 전환하는 것이 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
